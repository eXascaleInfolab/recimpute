{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8a0d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:38.276596Z",
     "start_time": "2022-04-20T16:35:37.488139Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from adtk.aggregator import OrAggregator\n",
    "from adtk.data import validate_series\n",
    "from adtk.detector import QuantileAD, InterQuartileRangeAD, GeneralizedESDTestAD, PersistAD\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, hamming_loss, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e522573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:38.322594Z",
     "start_time": "2022-04-20T16:35:38.277976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guillaume/recimpute\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7e1551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:39.090254Z",
     "start_time": "2022-04-20T16:35:38.323758Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Clustering.AbstractClustering import AbstractClustering\n",
    "from Clustering.ShapeBasedClustering import ShapeBasedClustering\n",
    "from Datasets.Dataset import Dataset\n",
    "from Datasets.TrainingSet import TrainingSet\n",
    "from Labeling.ImputationTechniques.ImputeBenchLabeler import ImputeBenchLabeler\n",
    "from Labeling.ImputationTechniques.KiviatRulesLabeler import KiviatRulesLabeler\n",
    "from Labeling import AbstractLabeler\n",
    "from FeaturesExtraction.TSFreshFeaturesExtractor import TSFreshFeaturesExtractor\n",
    "from FeaturesExtraction.KiviatFeaturesExtractor import KiviatFeaturesExtractor\n",
    "from Utils.Utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Experiments/results'):\n",
    "    os.makedirs('Experiments/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1130fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:39.539746Z",
     "start_time": "2022-04-20T16:35:39.521550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset.CONF['USE_LIST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc2b569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:50.276809Z",
     "start_time": "2022-04-20T16:35:39.841594Z"
    }
   },
   "outputs": [],
   "source": [
    "CLUSTERER = ShapeBasedClustering()\n",
    "DATASETS = Dataset.instantiate_from_dir(CLUSTERER)\n",
    "IB_LABELER = ImputeBenchLabeler.get_instance()\n",
    "IB_LABELER_PROPERTIES = IB_LABELER.get_default_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052d85ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:50.294925Z",
     "start_time": "2022-04-20T16:35:50.278480Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_by_name(datasets, name):\n",
    "    for dataset in datasets:\n",
    "        if dataset.name == name:\n",
    "            return dataset\n",
    "    raise Exception('Data set not found: %s.' % name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ed5de",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c4dc08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:50.554665Z",
     "start_time": "2022-04-20T16:35:50.295939Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def __init_test_set(datasets, strategy, test_size_percentage):\n",
    "    test_set = []\n",
    "    if strategy == 'one_cluster_every_two_dataset':\n",
    "        # reserve one cluster every two data sets for the test set\n",
    "        for dataset in datasets[::2]:\n",
    "            for cid in dataset.cids:\n",
    "                test_set.append(cid)\n",
    "                break\n",
    "        return 'clusters', test_set\n",
    "    elif strategy == 'clusters_percentage':\n",
    "        # reserve a fixed percentage of randomly selected clusters for the test set\n",
    "        all_cids = list(chain.from_iterable([ds.cids for ds in datasets]))\n",
    "        nb_test_clusters = int(np.ceil(len(all_cids) * test_size_percentage))\n",
    "        test_set = rdm.sample(all_cids, nb_test_clusters)\n",
    "        return 'clusters', test_set\n",
    "    elif strategy == 'ts_percentage':\n",
    "        all_ts_ids = list(range(0, sum(ds.nb_timeseries for ds in datasets)))\n",
    "        nb_test_sequences = int(np.ceil(len(all_ts_ids) * test_size_percentage))\n",
    "        test_set = rdm.sample(all_ts_ids, nb_test_sequences)\n",
    "        return 'timeseries', test_set\n",
    "\n",
    "    else:\n",
    "        raise Exception('Test set reservation strategy not implemented: ', strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82dbb5cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:35:50.681660Z",
     "start_time": "2022-04-20T16:35:50.556472Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def custom_load(datasets, data_to_load, clusterer, labeler, labeler_properties, test_set_level, test_set_ids):\n",
    "    all_complete_datasets = []\n",
    "        \n",
    "    for dataset in datasets:\n",
    "\n",
    "        # load labels - dataset_labels: df w/ 2 cols: Time Series ID and Label\n",
    "        dataset_labels, labels_set = dataset.load_labels(labeler, labeler_properties)\n",
    "        dataset_labels.set_index('Time Series ID', inplace=True)\n",
    "        \n",
    "        # load cassignment if the column is not there already\n",
    "        dataset_cassignment = dataset.load_cassignment(clusterer)\n",
    "        dataset_cassignment.set_index('Time Series ID', inplace=True)\n",
    "        \n",
    "        # load time series\n",
    "        dataset_series = dataset.load_timeseries(transpose=True)\n",
    "        dataset_series.columns = range(dataset_series.shape[1])\n",
    "        \n",
    "        to_concat = [dataset_labels, dataset_cassignment, dataset_series]\n",
    "        # concat data set's labels, series and cassignment\n",
    "        complete_dataset = pd.concat(to_concat, axis=1)\n",
    "        \n",
    "        complete_dataset['Data Set Name'] = dataset.name\n",
    "        \n",
    "        all_complete_datasets.append(complete_dataset) # this list contains train, val & test sets\n",
    "        \n",
    "    # merge the complete data sets (each row is a time serie's info)\n",
    "    all_complete_datasets_df = pd.concat(all_complete_datasets, axis=0)\n",
    "    \n",
    "    # create new time series ID (tid must be unique across ALL data sets)\n",
    "    all_complete_datasets_df.index = list(range(0, all_complete_datasets_df.shape[0]))\n",
    "    all_complete_datasets_df.index.name = 'New Time Series ID'\n",
    "\n",
    "    df_to_return = None\n",
    "    if data_to_load != 'all':\n",
    "        # only keep either the test set or both the training and validation sets\n",
    "        if test_set_level == 'clusters':\n",
    "            mask = all_complete_datasets_df['Cluster ID'].isin(test_set_ids) # series that are in the test set\n",
    "        elif test_set_level == 'datasets':\n",
    "            mask = all_complete_datasets_df['Data Set Name'].isin(test_set_ids) # series that are in the test set\n",
    "        elif test_set_level == 'timeseries':\n",
    "            mask = all_complete_datasets_df.index.isin(test_set_ids) # series that are in the test set\n",
    "        mask = mask if data_to_load == 'test' else ~mask\n",
    "        df_to_return = all_complete_datasets_df.loc[mask]\n",
    "    else:\n",
    "        # keep all data\n",
    "        df_to_return = all_complete_datasets_df\n",
    "\n",
    "    assert df_to_return is not None and labels_set is not None\n",
    "    return df_to_return, labels_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ecf0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:06.612808Z",
     "start_time": "2022-04-20T16:35:50.683036Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_set_level, test_set_ids = __init_test_set(DATASETS, 'ts_percentage', .35)\n",
    "all_data_info, labels_set = custom_load(\n",
    "    DATASETS, \n",
    "    'all', \n",
    "    CLUSTERER, \n",
    "    IB_LABELER, IB_LABELER_PROPERTIES, \n",
    "    test_set_level, test_set_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d403c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:06.644969Z",
     "start_time": "2022-04-20T16:38:06.614289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>6240</th>\n",
       "      <th>6241</th>\n",
       "      <th>6242</th>\n",
       "      <th>6243</th>\n",
       "      <th>6244</th>\n",
       "      <th>6245</th>\n",
       "      <th>6246</th>\n",
       "      <th>6247</th>\n",
       "      <th>6248</th>\n",
       "      <th>6249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Time Series ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rosl</td>\n",
       "      <td>7935</td>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.113988</td>\n",
       "      <td>-0.127480</td>\n",
       "      <td>-0.130141</td>\n",
       "      <td>-0.121514</td>\n",
       "      <td>-0.114630</td>\n",
       "      <td>-0.103433</td>\n",
       "      <td>-0.091134</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svt</td>\n",
       "      <td>7936</td>\n",
       "      <td>-0.124929</td>\n",
       "      <td>-0.113072</td>\n",
       "      <td>-0.102470</td>\n",
       "      <td>-0.091563</td>\n",
       "      <td>-0.071726</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>-0.039614</td>\n",
       "      <td>-0.028974</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svt</td>\n",
       "      <td>7936</td>\n",
       "      <td>-0.072244</td>\n",
       "      <td>-0.069892</td>\n",
       "      <td>-0.056518</td>\n",
       "      <td>-0.046070</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>-0.024464</td>\n",
       "      <td>-0.007726</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 6253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Label  Cluster ID         0         1         2         3  \\\n",
       "New Time Series ID                                                             \n",
       "0                   rosl        7935 -0.114538 -0.113988 -0.127480 -0.130141   \n",
       "1                    svt        7936 -0.124929 -0.113072 -0.102470 -0.091563   \n",
       "2                    svt        7936 -0.072244 -0.069892 -0.056518 -0.046070   \n",
       "\n",
       "                           4         5         6         7  ...  6240  6241  \\\n",
       "New Time Series ID                                          ...               \n",
       "0                  -0.121514 -0.114630 -0.103433 -0.091134  ...   NaN   NaN   \n",
       "1                  -0.071726 -0.058273 -0.039614 -0.028974  ...   NaN   NaN   \n",
       "2                  -0.033572 -0.024464 -0.007726  0.013688  ...   NaN   NaN   \n",
       "\n",
       "                    6242  6243  6244  6245  6246  6247  6248  6249  \n",
       "New Time Series ID                                                  \n",
       "0                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[3 rows x 6253 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d07319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:06.883100Z",
     "start_time": "2022-04-20T16:38:06.646498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70879, 6253)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f152c",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0d07db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:06.984881Z",
     "start_time": "2022-04-20T16:38:06.884364Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sample_cluster_2and10(all_timeseries, cluster, cluster_id):\n",
    "    # sample 2 series from the given cluster and 10 from the ~cluster's dataset\n",
    "    \n",
    "    # select all the data set's sequences except the ones from the cluster we want to label\n",
    "    available_timeseries = pd.concat([all_timeseries, cluster]).drop_duplicates(keep=False)\n",
    "    # number of time series to feed to the benchmark in addition to the sequence we want to label and a second sequence from its cluster\n",
    "    N_to_sample = min(ImputeBenchLabeler.CONF['NB_TS_FOR_BCHMK'], available_timeseries.shape[0])\n",
    "\n",
    "    sequences_to_use = pd.concat([\n",
    "        # 1st (and 2nd if cluster has at least 2 series) seq of cluster we want to label (benchmark will try to reconstruct this one)\n",
    "        *[cluster.iloc[i].to_frame().T for i in range(0, int(cluster.shape[0] > 1)+1)],\n",
    "        # N sequences from the same data set but not the same cluster\n",
    "        available_timeseries.sample(N_to_sample, replace=False) \n",
    "    ])\n",
    "\n",
    "    if sequences_to_use.shape[0] < 5:\n",
    "        nb_seq_to_add = 5 - sequences_to_use.shape[0]\n",
    "        if cluster.shape[0] - 2 >= nb_seq_to_add:\n",
    "            sequences_to_use = pd.concat([\n",
    "                sequences_to_use,\n",
    "                *[cluster.iloc[-i-1].to_frame().T for i in range(nb_seq_to_add)]\n",
    "            ])\n",
    "        else: raise Exception('The data set does not have enough time series for the ImputeBench benchmark to run properly.')\n",
    "\n",
    "    return sequences_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d0a20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:07.126388Z",
     "start_time": "2022-04-20T16:38:06.986271Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _get_irregularity_score(timeseries):\n",
    "    all_anomalies = []\n",
    "    for _, s_ in timeseries.iterrows(): # for each time series\n",
    "        s = validate_series(s_)\n",
    "\n",
    "        detectors = [\n",
    "            QuantileAD(high=0.99, low=0.01),\n",
    "            #    compares each time series value with historical quantiles\n",
    "\n",
    "            InterQuartileRangeAD(c=1.5),\n",
    "            #    based on simple historical statistics, based on interquartile range (IQR)\n",
    "\n",
    "            GeneralizedESDTestAD(alpha=0.3),\n",
    "            #    detects anomaly based on generalized extreme Studentized deviate (ESD) test\n",
    "\n",
    "            PersistAD(c=3.0, side='positive'),\n",
    "            #    compares each time series value with its previous values\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            all_anomalies.extend([d.fit_detect(s) for d in detectors])\n",
    "        except:\n",
    "            all_anomalies.extend([np.zeros(len(s), dtype=bool) for d in detectors])\n",
    "\n",
    "    all_anomalies = OrAggregator().aggregate(pd.DataFrame(np.array(all_anomalies).T, index=s.index))\n",
    "    all_anomalies_bool = all_anomalies.astype('bool')\n",
    "    anomalies_distribution = all_anomalies_bool.value_counts(normalize=False)\n",
    "    anomalies_distribution = anomalies_distribution[True] if True in anomalies_distribution else 0\n",
    "    anomalies_percentage = anomalies_distribution / len(s)\n",
    "\n",
    "    return anomalies_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce65b7cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T16:38:07.425250Z",
     "start_time": "2022-04-20T16:38:07.127933Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compute_features(dataset, cluster):\n",
    "    date_range = {'start': '1974-1-1', 'periods': cluster.shape[1], 'freq': '10min'}\n",
    "    cluster.columns = pd.date_range(**date_range)\n",
    "    \n",
    "    # feature 1: length\n",
    "    length = dataset.timeseries_length\n",
    "\n",
    "    # feature 2: irregularity score\n",
    "    irregularity = _get_irregularity_score(cluster)\n",
    "\n",
    "    # feature 3: pairwise correlation\n",
    "    corr_matrix = np.array(cluster.T.corr())\n",
    "    corr_upper_values = np.array(Utils.strictly_upper_triang_val(corr_matrix))\n",
    "    correlation = corr_upper_values[~np.isnan(corr_upper_values)] # (remove NaNs)\n",
    "\n",
    "    features_dict = {'Cluster ID': [None], 'Length': [length], 'Irregularity': [irregularity], 'Correlation': [correlation]}\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b424d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:26:33.312026Z",
     "start_time": "2022-04-21T11:26:33.288613Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _apply_rules(cluster_features):\n",
    "    # apply thresholds\n",
    "    thresholds = KiviatRulesLabeler.CONF['FEATURES_THRESHOLDS']\n",
    "    binary_cluster_features = {\n",
    "        'large_ts': int(cluster_features['Length'] >= thresholds['large_ts']),\n",
    "        'irregular_ts': int(cluster_features['Irregularity'] > thresholds['irregular_ts']),\n",
    "        'mixed_corr': int(cluster_features['STD Correlation'] > thresholds['mixed_corr']),\n",
    "        'high_corr': int(cluster_features['Median Correlation'] > thresholds['high_corr']),\n",
    "    }\n",
    "    #print(binary_cluster_features)\n",
    "\n",
    "    features_weights = KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']\n",
    "    kiviat_values = KiviatRulesLabeler.KIVIAT_VALUES\n",
    "\n",
    "    # compute a score for each algorithm\n",
    "    scores = {}\n",
    "    for algo in KiviatRulesLabeler.CONF['ALGORITHMS_LIST']:\n",
    "        score = features_weights['efficient'] * kiviat_values[algo]['efficient']\n",
    "        for name, value in binary_cluster_features.items():\n",
    "            score += value * features_weights[name] * kiviat_values[algo][name]\n",
    "        scores[algo] = score\n",
    "\n",
    "    # label is the algorithms producing the highest score\n",
    "    #return sorted(scores.items(), key=(lambda i: i[1]), reverse=True)\n",
    "    return sorted(scores.keys(), key=(lambda key: scores[key]), reverse=True) # return sorted list of algos algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e209906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:42:13.038591Z",
     "start_time": "2022-04-21T12:42:13.015678Z"
    }
   },
   "outputs": [],
   "source": [
    "KiviatRulesLabeler.CONF['FEATURES_THRESHOLDS']['large_ts'] = 750\n",
    "KiviatRulesLabeler.CONF['FEATURES_THRESHOLDS']['irregular_ts'] = .10\n",
    "KiviatRulesLabeler.CONF['FEATURES_THRESHOLDS']['mixed_corr'] = .20\n",
    "KiviatRulesLabeler.CONF['FEATURES_THRESHOLDS']['high_corr'] = .70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f034503e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:42:13.580679Z",
     "start_time": "2022-04-21T12:42:13.317605Z"
    }
   },
   "outputs": [],
   "source": [
    "KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']['efficient'] = 0.0 # just for runtime\n",
    "KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']['large_ts'] = 0.0 # just for runtime\n",
    "KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']['irregular_ts'] = 0.5\n",
    "KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']['mixed_corr'] = 0.8\n",
    "KiviatRulesLabeler.CONF['FEATURES_WEIGHTS']['high_corr'] = 0.8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35735c43",
   "metadata": {},
   "source": [
    "'cdrec': \n",
    "    {'efficient': 1, 'large_ts': 3, 'irregular_ts': 3, 'mixed_corr': 5, 'high_corr': 3},\n",
    "'dynammo': \n",
    "    {'efficient': 0, 'large_ts': 0, 'irregular_ts': 5, 'mixed_corr': 4, 'high_corr': 3},\n",
    "'softimp': \n",
    "    {'efficient': 1, 'large_ts': 3, 'irregular_ts': 4, 'mixed_corr': 3, 'high_corr': 2},\n",
    "'svdimp': \n",
    "    {'efficient': 1, 'large_ts': 4, 'irregular_ts': 3, 'mixed_corr': 4, 'high_corr': 3},\n",
    "'stmvl':\n",
    "    {'efficient': 0, 'large_ts': 2, 'irregular_ts': 2, 'mixed_corr': 1, 'high_corr': 5},\n",
    "'trmf': \n",
    "    {'efficient': 0, 'large_ts': 1, 'irregular_ts': 3, 'mixed_corr': 4, 'high_corr': 3},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8942f793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:42:39.101128Z",
     "start_time": "2022-04-21T12:42:39.079878Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_cids_to_use = len(all_data_info['Cluster ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc608898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T13:09:08.819643Z",
     "start_time": "2022-04-21T13:09:08.795077Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _get_labels(cid):\n",
    "    ds_name = all_data_info.loc[all_data_info['Cluster ID'] == cid]['Data Set Name'].to_numpy()[0]\n",
    "    all_timeseries = all_data_info.loc[all_data_info['Data Set Name'] == ds_name]\n",
    "    cluster = all_data_info.loc[all_data_info['Cluster ID'] == cid]\n",
    "    sample = sample_cluster_2and10(all_timeseries, cluster, cid)\n",
    "    \n",
    "    # compute Kiviat Features of this sample\n",
    "    sample = sample.iloc[:, ~sample.columns.isin(['Data Set Name', 'Cluster ID', 'Label'])].dropna(axis=1)\n",
    "    sample = sample.apply(pd.to_numeric, errors='coerce')\n",
    "    features_dict = compute_features(\n",
    "        get_dataset_by_name(DATASETS, ds_name), \n",
    "        sample\n",
    "    )\n",
    "    \n",
    "    features_dict['Cluster ID'] = cid\n",
    "    features = pd.DataFrame.from_dict(features_dict)\n",
    "    features = features.set_index('Cluster ID')\n",
    "    \n",
    "    features['STD Correlation'] = features['Correlation'].apply(np.std)\n",
    "    features['Median Correlation'] = features['Correlation'].apply(np.median)\n",
    "    features = features.drop(columns=['Correlation'])\n",
    "    \n",
    "    features_per_cid[cid] = features # TODO delete\n",
    "    \n",
    "    # label the sample\n",
    "    label_preds = _apply_rules(features)\n",
    "    \n",
    "    return cid, label_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cd65a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:47:20.600399Z",
     "start_time": "2022-04-21T12:42:40.205461Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# do predictions\n",
    "y_pred_per_cid = {}\n",
    "features_per_cid = {}\n",
    "with Pool() as pool:\n",
    "    for res in tqdm(pool.imap_unordered(_get_labels, \n",
    "                                        rdm.sample(all_data_info['Cluster ID'].unique().tolist(), nb_cids_to_use)), \n",
    "                    total=nb_cids_to_use):\n",
    "        cid, label = res\n",
    "        y_pred_per_cid[cid] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "868133ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:13:38.873219Z",
     "start_time": "2022-04-21T12:13:38.016710Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(y_pred_per_cid).to_csv('Experiments/results/kiviat_y_pred_per_cid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2f32b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ccfae48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:48:48.655910Z",
     "start_time": "2022-04-21T12:48:48.632549Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compute_at_k_scores(y_true, y_preds, scores, K=3):\n",
    "    # rank at which each y_true is found in the sorted y_pred_proba (list of len = len(y_true))\n",
    "    ranks = [y_preds_i.index(y_true_i) + 1 if y_true_i in y_preds_i else np.inf\n",
    "             for y_true_i, y_preds_i in zip(y_true, y_preds)] \n",
    "\n",
    "    scores['Mean Reciprocal Rank'] = (1 / len(y_true)) * sum(1 / rank_i for rank_i in ranks)\n",
    "    # average prec@K and recall@k\n",
    "    prec_at_k = lambda K, rank_y_true: int(rank_y_true <= K) / K\n",
    "    scores['Precision@3'] = sum(prec_at_k(K, rank_y_true) for rank_y_true in ranks) / len(y_true)\n",
    "    recall_at_k = lambda K, rank_y_true: int(rank_y_true <= K) / 1\n",
    "    scores['Recall@3'] = sum(recall_at_k(K, rank_y_true) for rank_y_true in ranks) / len(y_true)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01e616de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T12:48:49.171915Z",
     "start_time": "2022-04-21T12:48:49.155534Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def clean_preds(y_true, y_pred, y_preds, labels_set):\n",
    "    # remove test entries where true label isn't one that can be predicted by the Kiviat rules\n",
    "    df = pd.DataFrame((y_true, y_pred))\n",
    "    df = df[~df.isin(set(labels_set) - set(np.unique(y_pred)))].dropna(axis=1)\n",
    "    y_true_ = df.iloc[0].to_numpy()\n",
    "    y_pred_ = df.iloc[1].to_numpy()\n",
    "    y_preds_ = [y_pred_i for i,y_pred_i in enumerate(y_preds) if i in df.columns.tolist()]\n",
    "    assert y_pred_.shape[0] == y_true_.shape[0] == len(y_preds_)\n",
    "    print(y_true_.shape)\n",
    "    return y_true_, y_pred_, y_preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "664f36a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T13:09:12.983148Z",
     "start_time": "2022-04-21T13:09:12.958685Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def print_scores(y_true, y_pred, y_preds, labels_set):\n",
    "    average_strat = 'weighted'\n",
    "    scores = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred, normalize=True, sample_weight=None), \n",
    "        'F1-Score': f1_score(y_true=y_true, y_pred=y_pred, average=average_strat, zero_division=0),\n",
    "        'Precision': precision_score(y_true=y_true, y_pred=y_pred, average=average_strat, zero_division=0).tolist(), \n",
    "        'Recall': recall_score(y_true=y_true, y_pred=y_pred, average=average_strat, zero_division=0).tolist(),\n",
    "        'Hamming Loss': hamming_loss(y_true, y_pred),\n",
    "    }\n",
    "    scores = compute_at_k_scores(y_true, y_preds, scores, K=3)\n",
    "    print(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1bb2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T13:06:52.068463Z",
     "start_time": "2022-04-27T13:06:13.288235Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "y_true, y_preds, y_pred = [], [], []\n",
    "y_true_per_category = {category: [] \n",
    "                       for category in set(Dataset.CONF['CATEGORIES'].values())}\n",
    "y_pred_per_category = {category: [] \n",
    "                       for category in set(Dataset.CONF['CATEGORIES'].values())}\n",
    "y_preds_per_category = {category: [] \n",
    "                        for category in set(Dataset.CONF['CATEGORIES'].values())}\n",
    "for row in all_data_info.itertuples(index=False):\n",
    "    if row[all_data_info.columns.get_loc('Cluster ID')] in y_pred_per_cid:\n",
    "        true_label = row[all_data_info.columns.get_loc('Label')]\n",
    "        pred_labels = y_pred_per_cid[row[all_data_info.columns.get_loc('Cluster ID')]]\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_preds.append(pred_labels)\n",
    "        y_pred.append(pred_labels[0])\n",
    "        \n",
    "        ds_name = row[all_data_info.columns.get_loc('Data Set Name')]\n",
    "        category = Dataset.CONF['CATEGORIES'][ds_name]\n",
    "        y_true_per_category[category].append(true_label)\n",
    "        y_preds_per_category[category].append(pred_labels)\n",
    "        y_pred_per_category[category].append(pred_labels[0])\n",
    "        \n",
    "print('\\n\\n============================================================\\n', '\\033[1m Average metrics: \\033[0m')\n",
    "y_true_, y_pred_, y_preds_ = clean_preds(y_true, y_pred, y_preds, labels_set)\n",
    "print_scores(y_true_, y_pred_, y_preds_, labels_set)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_true_, y_pred=y_pred_, xticks_rotation=45)\n",
    "plt.show()\n",
    "\n",
    "#print('\\n\\n============================================================\\n', '\\033[1m Average metrics per category: \\033[0m')\n",
    "#for category in y_true_per_category.keys():\n",
    "#    y_true_per_category[category], y_pred_per_category[category], y_preds_per_category[category] = clean_preds(\n",
    "#        y_true_per_category[category], y_pred_per_category[category], y_preds_per_category[category], \n",
    "#        labels_set\n",
    "#    )\n",
    "#    print('\\n~~ Category: %s ~~' % category)\n",
    "#    print_scores(y_true_per_category[category], y_pred_per_category[category], y_preds_per_category[category], labels_set)\n",
    "#\n",
    "#    ConfusionMatrixDisplay.from_predictions(y_true=y_true_per_category[category], y_pred=y_pred_per_category[category], xticks_rotation=45)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1999226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
